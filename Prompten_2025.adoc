= Prompting-Techniken für 2025: Überblick und Besonderheiten für Reasoning-Modelle

== Einleitung

Das Prompt Engineering hat sich 2025 stark weiterentwickelt. Neben klassischen Methoden sind zahlreiche fortgeschrittene und teils ausgefallene Techniken entstanden, die die Leistungsfähigkeit moderner LLMs und Reasoning-Modelle voll ausschöpfen. Im Folgenden findest du eine umfassende Übersicht aller relevanten Prompting-Techniken – inklusive Besonderheiten für Reasoning-Modelle.

==  1. Standard- und Fortgeschrittene Prompting-Techniken

== Zero-Shot Prompting**
  - Klare, direkte Anweisung ohne Beispiele.
  - Ideal für einfache oder bekannte Aufgaben[6][8][12].

== Few-Shot Prompting**
  - 2–5 Beispiele als Kontext im Prompt.
  - Verbessert Formatkonsistenz und domänenspezifische Aufgaben[6][8][12].

== Chain-of-Thought (CoT) Prompting**
  - Explizite Aufforderung zum schrittweisen Denken („Denke Schritt für Schritt“).
  - Besonders effektiv bei komplexen, logischen Aufgaben[6][8][10][12].

== Self-Consistency Prompting**
  - Mehrere Reasoning-Pfade generieren lassen, dann den konsistentesten Output wählen.
  - Reduziert Fehler bei komplexen Aufgaben[6][8][10].

== Tree-of-Thought (ToT) Prompting**
  - Das Modell exploriert verschiedene Lösungswege als Baumstruktur und wählt den besten Pfad aus[8].

== Prompt Chaining**
  - Mehrere Prompts werden sequentiell verbunden, um komplexe Aufgaben in Teilschritte zu zerlegen[8].

== Meta Prompting**
  - Der Prompt gibt nur die Struktur oder das Vorgehen vor, nicht die konkreten Inhalte.
  - Fördert Generalisierung und logische Konsistenz[6][8].

== Retrieval-Augmented Generation (RAG)**
  - Externe Wissensquellen werden eingebunden, um die Antwort zu verbessern[8][10].

== ReAct (Reasoning + Acting)**
  - Das Modell kombiniert logisches Denken mit Aktionen (z.B. Tool-Nutzung)[8].

== Automatic Reasoning and Tool-use (ART)**
  - Das Modell entscheidet selbstständig, welche Tools oder Datenquellen genutzt werden sollen[8].

== Persona-/Role-Prompting**
  - Das Modell erhält eine explizite Rolle („Du bist ein Senior Developer...“), um Stil und Fachlichkeit zu steuern[10][12][13].

== Structured Output Specification**
  - Das gewünschte Ausgabeformat (z.B. JSON, Tabelle) wird explizit vorgegeben[10].

== Self-Correction/Reflection Prompts**
  - Das Modell wird aufgefordert, die eigene Antwort zu überprüfen und zu verbessern („Überarbeite deine Antwort auf Fehler.“)[1][10].

== Data-Driven Prompting**
  - Relevante Daten oder Fakten werden direkt im Prompt mitgegeben, um die Genauigkeit zu erhöhen[3].

== Recursive Self-Improvement Prompting (RSIP)**
  - Das Modell erstellt einen Entwurf, bewertet Schwächen und verbessert sich iterativ selbst[1].

== Context-Aware Decomposition (CAD)**
  - Komplexe Aufgaben werden kontextbewusst in Teilprobleme zerlegt[1].

== Multimodal Prompting**
  - Kombination aus Text, Bildern und anderen Medien im Prompt[2].

==  2. Ausgefallene und experimentelle Techniken

== Prompt Ensembling**
  - Mehrere verschiedene Prompts werden parallel genutzt, die Ergebnisse aggregiert.

== Adversarial Prompting**
  - Das Modell wird gezielt mit schwierigen oder irreführenden Prompts getestet, um Schwachstellen zu identifizieren.

== Prompt Injection/Editing**
  - Prompts werden dynamisch zur Laufzeit angepasst, z.B. durch User-Feedback oder externe Events.

== Self-Prompting**
  - Das Modell generiert selbst die für die Aufgabe optimalen Prompts („Prompt-Reflexion“)[7].

== Prompt Memory**
  - Das Modell nutzt vergangene Prompts und Antworten als Kontext für aktuelle Aufgaben[2].

==  3. Besonderheiten für Reasoning-Modelle (z.B. OpenAI o1/o3, Claude 4)

[NOTE]
== == 
Reasoning-Modelle verhalten sich beim Prompting anders als klassische LLMs. Die wichtigsten Unterschiede und Empfehlungen:

== Prompts müssen besonders klar, präzise und direkt sein.**
  - Vage oder zu komplexe Prompts führen zu schlechteren Ergebnissen[11][13].

== Chain-of-Thought Prompting ist meist unnötig oder sogar kontraproduktiv.**
  - Reasoning-Modelle führen intern bereits logische Analysen aus. Explizite CoT-Aufforderungen können die Leistung verschlechtern[11][9].

== Kurze, explizite Aufgabenstellungen bevorzugen.**
  - Lange, verschachtelte Prompts vermeiden. Beispiel:
+
----
GUT: "Fasse die drei wichtigsten Erkenntnisse des Artikels zusammen."
SCHLECHT: "Bitte analysiere den Artikel Schritt für Schritt und fasse dann alles in einer logisch kohärenten Struktur zusammen."
----

== Kontext gezielt und knapp mitgeben.**
  - Nur relevante Informationen bereitstellen, um Überforderung zu vermeiden[13].

== Strukturierte Output-Vorgaben funktionieren sehr gut.**
  - JSON, Tabellen oder Bullet-Points explizit verlangen[10][13].

== Feedback- und Selbstverbesserungs-Prompts sind weiterhin sinnvoll.**
  - Das Modell kann eigene Ausgaben reflektieren und verbessern[1][10].

== Self-Prompting und interne Reasoning-Chains**
  - Moderne Modelle generieren intern eigene „Prompts“ und Reasoning-Schritte, bevor sie antworten. Der Nutzer muss daher weniger explizit vorgeben, wie gedacht werden soll[7][9].

==  4. Vergleich Prompting klassischer LLMs vs. Reasoning-Modelle

| Technik/Empfehlung             | Klassische LLMs        | Reasoning-Modelle           |
|--------------------------------|------------------------|-----------------------------|
| Chain-of-Thought (CoT)         | Sehr hilfreich         | Meist unnötig/schädlich[11] |
| Prompt-Länge                   | Variabel               | So kurz/präzise wie möglich |
| Strukturierte Ausgaben         | Hilfreich              | Sehr empfehlenswert         |
| Feedback/Reflexion             | Optional               | Sehr effektiv               |
| Kontextmenge                   | Viel möglich           | Gezielt, knapp              |
| Self-Prompting                 | Kaum                   | Modell-intern Standard[7]   |

==  5. Best Practices für 2025

* Klare, explizite Anweisungen
* Relevanten Kontext bereitstellen, Überladung vermeiden
* Strukturierte Output-Vorgaben nutzen
* Feedback- und Selbstverbesserungs-Loops einbauen
* Bei Reasoning-Modellen: Keine expliziten CoT-Prompts, sondern auf interne Logik vertrauen
* Kombination mehrerer Techniken je nach Aufgabe ausprobieren

==  6. Quellen und weiterführende Hinweise

Die Empfehlungen basieren auf aktuellen Best Practices und Forschungsergebnissen aus 2025[1][2][3][6][8][9][10][11][12][13].

