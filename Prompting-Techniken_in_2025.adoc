:toc:
:toclevels: 2

= Prompting-Techniken für 2025: Überblick und Besonderheiten für Reasoning-Modelle

== Einleitung

Das Prompt Engineering hat sich 2025 stark weiterentwickelt. Neben klassischen Methoden sind zahlreiche fortgeschrittene und teils ausgefallene Techniken entstanden, die die Leistungsfähigkeit moderner LLMs und Reasoning-Modelle voll ausschöpfen. Im Folgenden findest du eine umfassende Übersicht aller relevanten Prompting-Techniken – inklusive Besonderheiten für Reasoning-Modelle.

== Standard- und Fortgeschrittene Prompting-Techniken

=== Zero-Shot Prompting
  - Klare, direkte Anweisung ohne Beispiele.
  - Ideal für einfache oder bekannte Aufgaben.

=== Few-Shot Prompting
  - 2–5 Beispiele als Kontext im Prompt.
  - Verbessert Formatkonsistenz und domänenspezifische Aufgaben.

=== Chain-of-Thought (CoT) Prompting
  - Explizite Aufforderung zum schrittweisen Denken („Denke Schritt für Schritt“).
  - Besonders effektiv bei komplexen, logischen Aufgaben.

=== Self-Consistency Prompting
  - Mehrere Reasoning-Pfade generieren lassen, dann den konsistentesten Output wählen.
  - Reduziert Fehler bei komplexen Aufgaben.

=== Tree-of-Thought (ToT) Prompting
  - Das Modell exploriert verschiedene Lösungswege als Baumstruktur und wählt den besten Pfad aus.

=== Prompt Chaining
  - Mehrere Prompts werden sequentiell verbunden, um komplexe Aufgaben in Teilschritte zu zerlegen.

=== Meta Prompting
  - Der Prompt gibt nur die Struktur oder das Vorgehen vor, nicht die konkreten Inhalte.
  - Fördert Generalisierung und logische Konsistenz.

=== Retrieval-Augmented Generation (RAG)
  - Externe Wissensquellen werden eingebunden, um die Antwort zu verbessern.

=== ReAct (Reasoning + Acting)
  - Das Modell kombiniert logisches Denken mit Aktionen (z.B. Tool-Nutzung).

=== Automatic Reasoning and Tool-use (ART)
  - Das Modell entscheidet selbstständig, welche Tools oder Datenquellen genutzt werden sollen.

=== Persona-/Role-Prompting
  - Das Modell erhält eine explizite Rolle („Du bist ein Senior Developer...“), um Stil und Fachlichkeit zu steuern.

=== Structured Output Specification
  - Das gewünschte Ausgabeformat (z.B. JSON, Tabelle) wird explizit vorgegeben.

=== Self-Correction/Reflection Prompts
  - Das Modell wird aufgefordert, die eigene Antwort zu überprüfen und zu verbessern („Überarbeite deine Antwort auf Fehler.“).

=== Data-Driven Prompting
  - Relevante Daten oder Fakten werden direkt im Prompt mitgegeben, um die Genauigkeit zu erhöhen.

=== Recursive Self-Improvement Prompting (RSIP)
  - Das Modell erstellt einen Entwurf, bewertet Schwächen und verbessert sich iterativ selbst.

=== Context-Aware Decomposition (CAD)
  - Komplexe Aufgaben werden kontextbewusst in Teilprobleme zerlegt.

=== Multimodal Prompting
  - Kombination aus Text, Bildern und anderen Medien im Prompt.

== Ausgefallene und experimentelle Techniken

=== Prompt Ensembling
  - Mehrere verschiedene Prompts werden parallel genutzt, die Ergebnisse aggregiert.

=== Adversarial Prompting
  - Das Modell wird gezielt mit schwierigen oder irreführenden Prompts getestet, um Schwachstellen zu identifizieren.

=== Prompt Injection/Editing
  - Prompts werden dynamisch zur Laufzeit angepasst, z.B. durch User-Feedback oder externe Events.

=== Self-Prompting
  - Das Modell generiert selbst die für die Aufgabe optimalen Prompts („Prompt-Reflexion“).

=== Prompt Memory
  - Das Modell nutzt vergangene Prompts und Antworten als Kontext für aktuelle Aufgaben.

== Besonderheiten für Reasoning-Modelle (z.B. OpenAI o1/o3, Claude 4)

Reasoning-Modelle verhalten sich beim Prompting anders als klassische LLMs. Die wichtigsten Unterschiede und Empfehlungen:

=== Prompts müssen besonders klar, präzise und direkt sein
  - Vage oder zu komplexe Prompts führen zu schlechteren Ergebnissen.

=== Chain-of-Thought Prompting ist meist unnötig oder sogar kontraproduktiv
  - Reasoning-Modelle führen intern bereits logische Analysen aus. Explizite CoT-Aufforderungen können die Leistung verschlechtern.

=== Kurze, explizite Aufgabenstellungen bevorzugen
  - Lange, verschachtelte Prompts vermeiden. Beispiel:
----
GUT: "Fasse die drei wichtigsten Erkenntnisse des Artikels zusammen."
SCHLECHT: "Bitte analysiere den Artikel Schritt für Schritt und fasse dann alles in einer logisch kohärenten Struktur zusammen."
----

=== Kontext gezielt und knapp mitgeben
  - Nur relevante Informationen bereitstellen, um Überforderung zu vermeiden.

=== Strukturierte Output-Vorgaben funktionieren sehr gut
  - JSON, Tabellen oder Bullet-Points explizit verlangen.

=== Feedback- und Selbstverbesserungs-Prompts sind weiterhin sinnvoll
  - Das Modell kann eigene Ausgaben reflektieren und verbessern.

=== Self-Prompting und interne Reasoning-Chains
  - Moderne Modelle generieren intern eigene „Prompts“ und Reasoning-Schritte, bevor sie antworten. Der Nutzer muss daher weniger explizit vorgeben, wie gedacht werden soll.

==  Vergleich Prompting klassischer LLMs vs. Reasoning-Modelle

[cols="1,1,1", options="header"]
|===
| Technik/Empfehlung             | Klassische LLMs        | Reasoning-Modelle

| Chain-of-Thought (CoT)         | Sehr hilfreich         | Meist unnötig/schädlich
| Prompt-Länge                   | Variabel               | So kurz/präzise wie möglich
| Strukturierte Ausgaben         | Hilfreich              | Sehr empfehlenswert
| Feedback/Reflexion             | Optional               | Sehr effektiv
| Kontextmenge                   | Viel möglich           | Gezielt, knapp
| Self-Prompting                 | Kaum                   | Modell-intern Standard
|===

== Best Practices für 2025

* Klare, explizite Anweisungen
* Relevanten Kontext bereitstellen, Überladung vermeiden
* Strukturierte Output-Vorgaben nutzen
* Feedback- und Selbstverbesserungs-Loops einbauen
* Bei Reasoning-Modellen: Keine expliziten CoT-Prompts, sondern auf interne Logik vertrauen
* Kombination mehrerer Techniken je nach Aufgabe ausprobieren
